# agents/recommender_agent.py

import os
from dotenv import load_dotenv
load_dotenv(dotenv_path="/Users/carterhe/Desktop/LLM4Rec/.env")

print("ğŸ§ª DEBUG: OPENAI_API_KEY =", os.getenv("OPENAI_API_KEY"))
print("ğŸ§ª DEBUG: OPENAI_API_BASE =", os.getenv("OPENAI_API_BASE"))

from tools.recommend_tool import recommend_videos
# from langchain_community.chat_models import ChatOpenAI
# âœ… æ­£ç¡®çš„å†™æ³•ï¼ˆæ”¯æŒ openai_api_baseï¼‰
from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, Tool
from langchain.agents.agent_types import AgentType
from langchain.tools import tool


@tool
def recommend(user_input: str) -> list[dict]:
    """æ¨èè§†é¢‘ï¼šæ¥å—ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œå¦‚â€œæˆ‘æƒ³çœ‹çŒ«çŒ«æç¬‘è§†é¢‘â€ï¼Œå†…éƒ¨è§£æä¸ºå…³é”®è¯ã€‚"""
    tags = user_input.replace("ï¼Œ", ",").replace("ã€", ",").replace(" ", ",").split(",")
    tags = [t.strip() for t in tags if t.strip()]
    print("ğŸ§ª æå–å…³é”®è¯:", tags)
    return recommend_videos(tags)


tools = [
    Tool.from_function(
        func=recommend,
        name="VideoRecommender",
        description=(
            "æ¨èè§†é¢‘å·¥å…·ï¼Œè¾“å…¥å‚æ•°æ˜¯ä¸€ä¸ªå…³é”®è¯åˆ—è¡¨ï¼Œä¾‹å¦‚ ['çŒ«çŒ«', 'æç¬‘']ã€‚\n"
            "ç”¨æˆ·ä¼šè¾“å…¥è‡ªç„¶è¯­è¨€æè¿°å…´è¶£ï¼Œä½ åº”è¯¥ä»ä¸­æå–å…³é”®è¯ï¼Œæ ¼å¼åŒ–ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ã€‚\n"
            "âš ï¸ æ³¨æ„ï¼šä¸è¦ä¼ å…¥å­—ç¬¦ä¸²ï¼Œè€Œæ˜¯ list[str]ã€‚\n"
            "ç¤ºä¾‹ï¼šç”¨æˆ·è¯´â€œæˆ‘æƒ³çœ‹çŒ«çŒ«æç¬‘è§†é¢‘â€ â†’ è¾“å…¥åº”ä¸º ['çŒ«çŒ«', 'æç¬‘']"
        )
    )
]



print("ğŸ§ª LLM initialized with:")
print("   - API_KEY =", os.getenv("OPENAI_API_KEY"))
print("   - BASE_URL =", os.getenv("OPENAI_API_BASE"))

llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0,
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    openai_api_base=os.getenv("OPENAI_API_BASE")
)



agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.OPENAI_FUNCTIONS,
    verbose=True
)

def get_recommender_agent():
    return agent


if __name__ == "__main__":
    from langchain_core.messages import HumanMessage
    print("ğŸ” Testing LLM directly...")

    try:
        response = llm.invoke([HumanMessage(content="ä½ æ˜¯è°ï¼Ÿ")])
        print("âœ… æ¨¡å‹è¿”å›ï¼š", response.content)
    except Exception as e:
        print("âŒ æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼š", e)
